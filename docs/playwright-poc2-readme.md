# POC 2: LLM-Driven AI/UX Agent - Setup & Usage

## Overview

POC 2 builds on POC 1 and adds:
- **LLM-driven decision making**: Claude 3.5 Sonnet decides what to do at each step
- **Real-time reasoning**: The LLM generates first-person reasoning for each action
- **Dynamic flow**: No fixed script - the agent adapts based on what it sees
- **AI UX Agent persona**: A new persona designed for systematic UI testing

## Prerequisites

### 1. Complete POC 1 Setup

Make sure POC 1 is working:
```bash
npm install
npm run playwright:install
```

### 2. Get an Anthropic API Key

1. Go to https://console.anthropic.com/
2. Create an account or sign in
3. Generate an API key
4. Copy the key (starts with `sk-ant-...`)

### 3. Set the API Key

**Option A: Environment variable (recommended)**
```bash
export ANTHROPIC_API_KEY="sk-ant-your-key-here"
```

**Option B: .env.local file**
Create `.env.local` in the project root:
```
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

## Running POC 2

### Start the App

```bash
npm run dev
```

### Run the LLM-Driven Test

```bash
# Set API key and run
ANTHROPIC_API_KEY="your-key" npm run playwright:ai-agent-v1

# Or if you set it in .env.local
npm run playwright:ai-agent-v1
```

## What Happens

1. **Playwright** launches browser and navigates to the app
2. **LLM Agent Loop** starts:
   - Observes current page state (title, visible text, available elements)
   - Sends page state + AI UX Agent persona to Claude
   - Claude decides: what action to take + why
   - Executes the action in the browser
   - Logs action + LLM reasoning to `EventLogger`
   - Repeats until Claude says "shouldContinue: false" or max steps reached
3. **Saves** video, trace, events.json, metadata.json

## Output Structure

Same as POC 1, with `mode: "llm-driven"` and LLM-generated reasoning:

```
playwright-runs/
├── run-llm-1734123456789/
│   ├── video.webm
│   ├── events.json       # Contains LLM reasoning
│   └── metadata.json     # Includes llmModel field
└── test-results/
    └── <testId>/
        └── trace.zip
```

### Example events.json

```json
[
  {
    "runId": "run-llm-1734123456789",
    "personaId": "ai-ux-agent",
    "stepIndex": 0,
    "screenId": "step-0",
    "targetSelector": "[data-element-id=\"goal-option-maximize\"]",
    "targetElementId": "goal-option-maximize",
    "action": "HOVER",
    "reasoningText": "I'm examining the 'Maximize Output' option to assess its clarity. The label is somewhat vague and could benefit from more specific language.",
    "status": "confused",
    "timestamp": 1734123457000
  },
  ...
]
```

Note: `reasoningText` is now generated by Claude based on the AI UX Agent's personality and goals!

## How It Works

### 1. Page State Extraction

```typescript
// lib/playwright/llm-agent.ts: extractPageState()
const pageState = {
  title: "Welcome to FocusFlow",
  url: "http://localhost:3000/app",
  visibleText: "What brings you here? Choose your main goal...",
  availableElements: [
    { id: "goal-option-maximize", text: "Maximize Output", type: "button" },
    { id: "goal-option-optimize", text: "Optimize Workflow", type: "button" },
    ...
  ],
  screenId: "step-0"
};
```

### 2. LLM Prompt Construction

```typescript
// System prompt defines the persona
const systemPrompt = `You are AI UX Agent, an autonomous AI agent that tests user interfaces systematically.

Your goals:
- Evaluate UI clarity and usability
- Identify confusing or ambiguous elements
- Complete tasks efficiently while noting friction points

Your preferences:
- Clear labeling and visual hierarchy
- Consistent interaction patterns
- Obvious primary actions

...`;

// User prompt provides current page state
const userPrompt = `Current page state:
Title: Welcome to FocusFlow
Screen: step-0
Available elements:
1. [button] "Maximize Output" (id: goal-option-maximize)
2. [button] "Optimize Workflow" (id: goal-option-optimize)
...

What do you do next? Respond with JSON:
{
  "action": "CLICK",
  "selector": "[data-element-id='goal-option-maximize']",
  "reasoning": "I'm clicking this to evaluate...",
  "status": "confused",
  "shouldContinue": true
}`;
```

### 3. LLM Decision Execution

```typescript
// Get decision from Claude
const decision = await getLLMDecision(persona, pageState);

// Execute in browser
await page.click(decision.selector);

// Log to events.json
await logger.logAction(
  decision.action,
  decision.selector,
  decision.reasoning, // LLM-generated!
  decision.status
);
```

## AI UX Agent Persona

Add to `lib/data/personas.ts`:

```typescript
{
  id: 'ai-ux-agent',
  name: 'AI UX Agent',
  avatarColor: '#6366f1',
  description: 'An autonomous AI agent that tests user interfaces systematically',
  goals: [
    'Evaluate UI clarity and usability',
    'Identify confusing or ambiguous elements',
    'Complete tasks efficiently while noting friction points',
  ],
  preferences: [
    'Clear labeling and visual hierarchy',
    'Consistent interaction patterns',
    'Obvious primary actions',
  ],
  painPoints: [
    'Ambiguous or jargon-heavy copy',
    'Unclear button purposes',
    'Poor visual hierarchy',
  ],
  tone: 'Analytical and objective. Notes observations clearly and directly.',
}
```

## Key Differences from POC 1

| Aspect | POC 1 (Scripted) | POC 2 (LLM-Driven) |
|--------|------------------|---------------------|
| **Actions** | Fixed sequence from `simulation-sequences.ts` | Decided by LLM at each step |
| **Reasoning** | Pre-written strings | Generated by Claude in real-time |
| **Flow** | Always follows the same path | Can adapt based on page state |
| **Setup** | No API key needed | Requires Anthropic API key |
| **Reliability** | 100% reproducible | May vary between runs |
| **Cost** | Free | ~$0.01-0.05 per run (tokens) |

## Configuration

### Max Steps

Change in `ai-ux-agent-v1.spec.ts`:

```typescript
const decisions = await runLLMPersonaFlow(
  page,
  persona,
  30, // Increase max steps
  process.env.ANTHROPIC_API_KEY
);
```

### LLM Model

Change in `lib/playwright/llm-agent.ts`:

```typescript
const response = await anthropic.messages.create({
  model: 'claude-3-5-sonnet-20241022', // Or 'claude-3-opus-20240229'
  temperature: 0.7, // Lower = more deterministic
  ...
});
```

### Timeout

Change in `playwright.config.ts`:

```typescript
export default defineConfig({
  timeout: 180 * 1000, // 3 minutes for LLM calls
  ...
});
```

## Troubleshooting

### "Error: ANTHROPIC_API_KEY not set"

Set the API key:
```bash
export ANTHROPIC_API_KEY="sk-ant-..."
```

### "Error: LLM response missing required fields"

Claude's JSON output was malformed. This can happen if:
- The prompt is too complex
- The page state is too large
- Claude got confused

**Fix**: Simplify the prompt or reduce `pageState.visibleText` length in `llm-agent.ts`.

### "Selector not found"

The LLM chose a selector that doesn't exist on the page. This means:
- The LLM didn't follow instructions to use exact selectors from the list
- The page changed between extraction and execution

**Fix**: Improve the prompt to be more strict about selector format.

### LLM keeps waiting instead of continuing

The LLM thinks the flow is complete or is stuck. Check:
- Is there an obvious next action?
- Are the available elements clear?
- Did the LLM set `shouldContinue: false`?

**Fix**: Adjust persona goals to be more explicit about completing the flow.

### Token costs are high

Each step costs tokens (input + output). To reduce:
- Lower `maxSteps`
- Reduce `pageState.visibleText` length
- Use `claude-3-haiku` instead of Sonnet (cheaper, less capable)

## Success Criteria

POC 2 is successful if:
- ✅ LLM makes decisions at each step
- ✅ Reasoning is generated in real-time and in-character
- ✅ Agent completes the onboarding flow
- ✅ events.json contains LLM reasoning
- ✅ Flow is different from POC 1 (adapts to page state)

## Demo Plan

For the hackathon:
1. Run POC 2 before demo to pre-record video
2. Show video in Mimica UI
3. Highlight LLM-generated reasoning in thought bubbles
4. Compare POC 1 (scripted) vs POC 2 (LLM) runs side-by-side
5. Explain how this works with any persona/app

## Next Steps

- Add AI UX Agent persona to `lib/data/personas.ts`
- Test with different LLM models (Sonnet vs Opus vs Haiku)
- Integrate with Mimica TKF (see POC 3 planning)
- Explore MCP wrapping (optional stretch)

